{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Produto Escalar em CUDA\n",
    "\n",
    "**Antes de rodar:** vá em `Runtime → Change runtime type → T4 GPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycuda -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "THREADS = 256\n",
    "\n",
    "mod = SourceModule(\"\"\"\n",
    "__global__ void dot_kernel(float *A, float *B, float *partial, int N) {\n",
    "    extern __shared__ float sdata[];\n",
    "\n",
    "    int tid = threadIdx.x;\n",
    "    int i   = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    sdata[tid] = (i < N) ? A[i] * B[i] : 0.0f;\n",
    "    __syncthreads();\n",
    "\n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (tid < s) sdata[tid] += sdata[tid + s];\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (tid == 0) partial[blockIdx.x] = sdata[0];\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "dot_kernel = mod.get_function('dot_kernel')\n",
    "print('Kernel compilado com sucesso!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_gpu(A, B):\n",
    "    A = np.array(A, dtype=np.float32)\n",
    "    B = np.array(B, dtype=np.float32)\n",
    "    N = len(A)\n",
    "    blocks = (N + THREADS - 1) // THREADS\n",
    "\n",
    "    partial = np.zeros(blocks, dtype=np.float32)\n",
    "\n",
    "    dot_kernel(\n",
    "        drv.In(A), drv.In(B), drv.Out(partial), np.int32(N),\n",
    "        block=(THREADS, 1, 1),\n",
    "        grid=(blocks, 1, 1),\n",
    "        shared=THREADS * 4\n",
    "    )\n",
    "\n",
    "    return float(partial.sum())\n",
    "\n",
    "def dot_cpu(A, B):\n",
    "    return float(np.dot(A, B))\n",
    "\n",
    "def run_test(label, A, B, expected):\n",
    "    gpu  = dot_gpu(A, B)\n",
    "    cpu  = dot_cpu(A, B)\n",
    "    diff = abs(gpu - cpu)\n",
    "    print(f'\\n--- {label} ---')\n",
    "    print(f'Resultado GPU : {gpu:.4f}')\n",
    "    print(f'Resultado CPU : {cpu:.4f}')\n",
    "    print(f'Esperado      : {expected:.4f}')\n",
    "    print(f'Diferenca     : {diff:.2e} -> {\"OK\" if diff < 1e-3 else \"ERRO\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tests",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Produto Escalar em CUDA')\n",
    "\n",
    "run_test('Exemplo 1', [1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0], 70.0)\n",
    "run_test('Exemplo 2', [0.5, 1.5, 2.5],       [2.0, 3.0, 4.0],       15.5)"
   ]
  }
 ]
}
